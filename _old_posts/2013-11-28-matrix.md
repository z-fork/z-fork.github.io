---
title: Matrix
layout: post
tags:
  - matrix
---

### 矩阵

    Space( 空间 )[ 存在一个集合, 定义一些概念, 满足一些性质 ]
      |
      |
    [ 定义了范数 ]
      |
      *
    赋范线性空间 ----------[ 定义角度 ]----------* 内积空间 --------[ 满足完备性 ]---------* 希尔伯特空间
      |
      |
    [ 满足完备性 ]
      |
      *
    巴拿赫空间


#### 基本特点

  1. 许多位置点组成.
  2. 点之间存在相对关系.  
  3. 空间中定义长度, 角度.
  4. 空间容纳运动, 一个点到另一个点的变换.

#### 线性空间

    线性空间中的任何一个对象, 通过选取基和坐标, 表达为向量形式. -- {1, 2}
    线性空间中的运动,被称为线性变换. -- {4}

    . 选定一组基
    . 用向量来描述空间中的任何一个对象
    . 用矩阵来描述该空间中的任何一个变换.

    变换方法 = 变换矩阵 * 向量.

#### 线性变换

    对于线性空间V中间任何两个不相同的对象x和y, 以及任意实数a和b, 有：

        T(aX + bY) = aT(X) + bT(Y)

    那么就称T为线性变换.

#### 基

    基看成是线性空间里的坐标系就可以了.

#### 选定一组基

    选定一个坐标系.

#### "矩阵是线性空间中的线性变换的一个描述. 在一个线性空间中, 只要我们选定一组基, 那么对于任何一个线性变换, 都能够用一个确定的矩阵来加以描述."

    理解这句话的关键, 在于把"线性变换”与"线性变换的一个描述”区别开.

    一个是那个对象, 一个是对那个对象的表述. 

    就好像我们熟悉的面向对象编程中, 一个对象可以有多个引用, 每个引用可以叫不同的名字, 但都是指的同一个对象. 如果还不形象, 那就干脆来个很俗的类比.

    比如有一头猪, 你打算给它拍照片, 只要你给照相机选定了一个镜头位置, 那么就可以给这头猪拍一张照片. 

    这个照片可以看成是这头猪的一个描述, 但只是一个片面的的描述, 因为换一个镜头位置给这头猪拍照, 能得到一张不同的照片, 也是这头猪的另一个片面的描述. 

    所有这样照出来的照片都是这同一头猪的描述, 但是又都不是这头猪本身.

    同样的, 对于一个线性变换, 只要你选定一组基, 那么就可以找到一个矩阵来描述这个线性变换. 

    换一组基, 就得到一个不同的矩阵. 

    所有这些矩阵都是这同一个线性变换的描述, 但又都不是线性变换本身.

两张猪的照片, 怎么知道这两张照片上的是同一头猪呢?

两个矩阵, 怎么知道这两个矩阵是描述的同一个线性变换呢? 

如果是同一个线性变换的不同的矩阵描述, 那就是本家兄弟了, 见面不认识, 岂不成了笑话.

好在, 我们可以找到同一个线性变换的矩阵兄弟们的一个性质, 那就是:

若矩阵A与B是同一个线性变换的两个不同的描述(之所以会不同, 是因为选定了不同的基, 也就是选定了不同的坐标系), 则一定能找到一个非奇异矩阵P, 使得A、B之间满足这样的关系:

$$A = P^{-1}BP$$

这就是相似矩阵的定义. 

没错, 所谓相似矩阵, 就是同一个线性变换的不同的描述矩阵. 

按照这个定义, 同一头猪的不同角度的照片也可以成为相似照片. 俗了一点, 不过能让人明白.

而在上面式子里那个矩阵P, 其实就是A矩阵所基于的基与B矩阵所基于的基这两组基之间的一个变换关系.

这个发现太重要了.

原来一族相似矩阵都是同一个线性变换的描述啊! 难怪这么重要! 

工科研究生课程中有矩阵论、矩阵分析等课程, 其中讲了各种各样的相似变换, 比如什么相似标准型, 对角化之类的内容, 都要求变换以后得到的那个矩阵与先前的那个矩阵式相似的, 为什么这么要求? 

因为只有这样要求, 才能保证变换前后的两个矩阵是描述同一个线性变换的.

当然, 同一个线性变换的不同矩阵描述, 从实际运算性质来看并不是不分好环的.

有些描述矩阵就比其他的矩阵性质好得多. 

这很容易理解, 同一头猪的照片也有美丑之分嘛. 

所以矩阵的相似变换可以把一个比较丑的矩阵变成一个比较美的矩阵, 而保证这两个矩阵都是描述了同一个线性变换. 

这样一来, 矩阵作为线性变换描述的一面, 基本上说清楚了. 

但是, 事情没有那么简单, 或者说, 线性代数还有比这更奇妙的性质, 那就是, 矩阵不仅可以作为线性变换的描述, 而且可以作为一组基的描述. 

而作为变换的矩阵, 不但可以把线性空间中的一个点给变换到另一个点去, 而且也能够把线性空间中的一个坐标系(基)表换到另一个坐标系(基)去. 

而且, 变换点与变换坐标系, 具有异曲同工的效果. 

线性代数里最有趣的奥妙, 就蕴含在其中. 

理解了这些内容, 线性代数里很多定理和规则会变得更加清晰、直觉. 

#### "运动等价于坐标系变换."

#### "对象的变换等价于坐标系的变换."

让我们想想, 达成同一个变换的结果, 比如把点(1, 1)变到点(2, 3)去, 你可以有两种做法.
  1. 坐标系不动, 点动, 把(1, 1)点挪到(2, 3)去. 
  2. 点不动, 变坐标系, 让x轴的度量(单位向量)变成原来的1/2, 让y轴的度量(单位向量)变成原先的1/3, 这样点还是那个点, 可是点的坐标就变成(2, 3)了. 方式不同, 结果一样. 

  1 - 把矩阵看成是运动描述, 矩阵与向量相乘就是使向量（点）运动的过程. 在这个方式下, 

	Ma = b

	的意思是：

	"向量a经过矩阵M所描述的变换, 变成了向量b."

  2 - 矩阵M描述了一个坐标系, 姑且也称之为M. 那么：

	Ma = Ib

	的意思是：

	"有一个向量, 它在坐标系M的度量下得到的度量结果向量为a, 那么它在坐标系I的度量下, 这个向量的度量结果是b."

	这里的I是指单位矩阵, 就是主对角线是1, 其他为零的矩阵. 

正因为是关键, 所以我得再解释一下. 

在M为坐标系的意义下, 如果把M放在一个向量a的前面, 形成Ma的样式, 我们可以认为这是对向量a的一个环境声明. 它相当于是说：

"注意了！这里有一个向量, 它在坐标系M中度量, 得到的度量结果可以表达为a. 可是它在别的坐标系里度量的话, 就会得到不同的结果. 为了明确, 我把M放在前面, 让你明白, 这是该向量在坐标系M中度量的结果."

那么我们再看孤零零的向量b：

  b

多看几遍, 你没看出来吗？它其实不是b, 它是：

  Ib

也就是说："在单位坐标系, 也就是我们通常说的直角坐标系I中, 有一个向量, 度量的结果是b."

而  Ma = Ib的意思就是说：

  "在M坐标系里量出来的向量a, 跟在I坐标系里量出来的向量b, 其实根本就是一个向量啊！”

这哪里是什么乘法计算, 根本就是身份识别嘛. 

从这个意义上我们重新理解一下向量. 向量这个东西客观存在, 但是要把它表示出来, 就要把它放在一个坐标系中去度量它, 然后把度量的结果（向量在各个坐标轴上的投影值）按一定顺序列在一起, 就成了我们平时所见的向量表示形式. 你选择的坐标系（基）不同, 得出来的向量的表示就不同. 向量还是那个向量, 选择的坐标系不同, 其表示方式就不同. 因此, 按道理来说, 每写出一个向量的表示, 都应该声明一下这个表示是在哪个坐标系中度量出来的. 表示的方式, 就是 Ma, 也就是说, 有一个向量, 在M矩阵表示的坐标系中度量出来的结果为a. 我们平时说一个向量是\\([2 3 5 7]^{T}\\), 隐含着是说, 这个向量在 I 坐标系中的度量结果是\\([2 3 5 7]^{T}\\), 因此, 这个形式反而是一种简化了的特殊情况. 

注意到, M矩阵表示出来的那个坐标系, 由一组基组成, 而那组基也是由向量组成的, 同样存在这组向量是在哪个坐标系下度量而成的问题. 也就是说, 表述一个矩阵的一般方法, 也应该要指明其所处的基准坐标系. 所谓M, 其实是 IM, 也就是说, M中那组基的度量是在 I 坐标系中得出的. 从这个视角来看, M×N也不是什么矩阵乘法了, 而是声明了一个在M坐标系中量出的另一个坐标系N, 其中M本身是在I坐标系中度量出来的. 

回过头来说变换的问题. 我刚才说, "固定坐标系下一个对象的变换等价于固定对象所处的坐标系变换”, 那个"固定对象”我们找到了, 就是那个向量. 但是坐标系的变换呢？我怎么没看见？

请看：

  Ma = Ib

我现在要变M为I, 怎么变？对了, 再前面乘以个\\(M^{-1}\\), 也就是M的逆矩阵. 换句话说, 你不是有一个坐标系M吗, 现在我让它乘以个\\(M^{-1}\\), 变成I, 这样一来的话, 原来M坐标系中的a在I中一量, 就得到b了. 

我建议你此时此刻拿起纸笔, 画画图, 求得对这件事情的理解. 比如, 你画一个坐标系, x轴上的衡量单位是2, y轴上的衡量单位是3, 在这样一个坐标系里, 坐标为(1, 1)的那一点, 实际上就是笛卡尔坐标系里的点(2, 3). 而让它原形毕露的办法, 就是把原来那个坐标系:

2 0
0 3

的x方向度量缩小为原来的1/2, 而y方向度量缩小为原来的1/3, 这样一来坐标系就变成单位坐标系I了. 保持点不变, 那个向量现在就变成了(2, 3)了. 

怎么能够让"x方向度量缩小为原来的1/2, 而y方向度量缩小为原来的1/3”呢？就是让原坐标系：

2 0
0 3

被矩阵：

1/2   0
 0   1/3

左乘. 而这个矩阵就是原矩阵的逆矩阵. 

下面我们得出一个重要的结论：

"对坐标系施加变换的方法, 就是让表示那个坐标系的矩阵与表示那个变化的矩阵相乘."

再一次, 矩阵的乘法变成了运动的施加. 只不过, 被施加运动的不再是向量, 而是另一个坐标系. 

如果你觉得你还搞得清楚, 请再想一下刚才已经提到的结论, 矩阵MxN, 一方面表明坐标系N在运动M下的变换结果, 另一方面, 把M当成N的前缀, 当成N的环境描述, 那么就是说, 在M坐标系度量下, 有另一个坐标系N. 这个坐标系N如果放在I坐标系中度量, 其结果为坐标系MxN. 

在这里, 我实际上已经回答了一般人在学习线性代数是最困惑的一个问题, 那就是为什么矩阵的乘法要规定成这样. 简单地说, 是因为：

1. 从变换的观点看, 对坐标系N施加M变换, 就是把组成坐标系N的每一个向量施加M变换. 

2. 从坐标系的观点看, 在M坐标系中表现为N的另一个坐标系, 这也归结为, 对N坐标系基的每一个向量, 把它在I坐标系中的坐标找出来, 然后汇成一个新的矩阵. 

3. 至于矩阵乘以向量为什么要那样规定, 那是因为一个在M中度量为a的向量, 如果想要恢复在I中的真像, 就必须分别与M中的每一个向量进行內积运算. 我把这个结论的推导留给感兴趣的朋友吧. 应该说, 其实到了这一步, 已经很容易了. 

综合以上1/2/3, 矩阵的乘法就得那么规定, 一切有根有据, 绝不是哪个神经病胡思乱想出来的. 

我已经无法说得更多了. 矩阵又是坐标系, 又是变换. 到底是坐标系, 还是变换, 已经说不清楚了, 运动与实体在这里统一了, 物质与意识的界限已经消失了, 一切归于无法言说, 无法定义了. 道可道, 非常道, 名可名, 非常名. 矩阵是在是不可道之道, 不可名之名的东西. 到了这个时候, 我们不得不承认, 我们伟大的线性代数课本上说的矩阵定义, 是无比正确的：

"矩阵就是由m行n列数放在一起组成的数学对象."

好了, 这基本上就是我想说的全部了. 还留下一个行列式的问题. 矩阵M的行列式实际上是组成M的各个向量按照平行四边形法则搭成一个n维立方体的体积. 对于这一点, 我只能感叹于其精妙, 却无法揭开其中奥秘了. 也许我掌握的数学工具不够, 我希望有人能够给我们大家讲解其中的道理了. 